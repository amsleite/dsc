{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import graphs libraries\n",
    "from ggplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import data and ROC function libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import roc_curve\n",
    "# import matrix transform library\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# import all classifier classifier algorithms library\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all data and split data into training and validation samples (40% validation + 60% traning)\n",
    "data_train = fetch_20newsgroups(subset='train', #categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "data_val = fetch_20newsgroups(subset='test', #categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "dim_train=len(data_train.target) # sample training size\n",
    "dim_val=len(data_val.target) # sample validation size\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.hist(data_train.target, bins=[1,2,3,4,5,6,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    ,facecolor='grey',alpha=0.5) # plot by category the training set\n",
    "plt.title(\"Traing Set\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the dataset in matrix\n",
    "vectorizer = HashingVectorizer(stop_words='english', non_negative=True, n_features=10000)\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "X_val = vectorizer.transform(data_val.data)\n",
    "y_train = data_train.target==0\n",
    "y_val = data_val.target==0\n",
    "\n",
    "# Running the Naive Bayes Model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train.todense(), y_train) # model dense matrix for sparse matrix\n",
    "\n",
    "# Calculating ROC Curve\n",
    "probs = clf.predict_proba(X_val.todense())[:,1]\n",
    "FalsePositive, TruePositive, thresh = roc_curve(y_val, probs)\n",
    "name=\"TodaBase\"\n",
    "results = pd.DataFrame({\n",
    "        \"nome\": name,\n",
    "        \"FalsePositive\": FalsePositive,\n",
    "        \"TruePositive\": TruePositive\n",
    "    })\n",
    "\n",
    "ggplot(aes(x='FalsePositive', y='TruePositive', color='name'), data=results) + \\\n",
    "    geom_step(size=3) + \\\n",
    "    geom_abline(color=\"black\") + \\\n",
    "    ggtitle(\"Text Classification: ROC 1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select similar categories\n",
    "categories = [\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x'\n",
    "]\n",
    "# import all data and split data into training and validation samples (40% validation + 60% traning)\n",
    "data_train2 = fetch_20newsgroups(subset='train', categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "data_val2 = fetch_20newsgroups(subset='test', categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "dim_train2=len(data_train.target) # sample training size\n",
    "dim_val2=len(data_val.target) # sample validation size\n",
    "\n",
    "# Transform the dataset in matrix\n",
    "vectorizer = HashingVectorizer(stop_words='english', non_negative=True, n_features=10000)\n",
    "X_train2 = vectorizer.fit_transform(data_train2.data)\n",
    "X_val2 = vectorizer.transform(data_val2.data)\n",
    "y_train2 = data_train2.target==0\n",
    "y_val2 = data_val2.target==0\n",
    "\n",
    "# Running the Naive Bayes Model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train2.todense(), y_train2) # model dense matrix for sparse matrix\n",
    "\n",
    "# Calculating ROC Curve\n",
    "probs2 = clf.predict_proba(X_val2.todense())[:,1]\n",
    "FalsePositive, TruePositive, thresh = roc_curve(y_val2, probs2)\n",
    "name=\"SimilarCat\"\n",
    "results2 = pd.DataFrame({\n",
    "        \"name\": name,\n",
    "        \"FalsePositive\": FalsePositive,\n",
    "        \"TruePositive\": TruePositive\n",
    "    })\n",
    "new_results=results\n",
    "new_results=new_results.append(results2)\n",
    "ggplot(aes(x='FalsePositive', y='TruePositive', color='name'), data=new_results) + \\\n",
    "    geom_step(size=3) + \\\n",
    "    geom_abline(color=\"black\") + \\\n",
    "    ggtitle(\"Text Classification: ROC 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select different categories\n",
    "categories = [\n",
    "'rec.motorcycles',\n",
    "    'sci.space'\n",
    "]\n",
    "# import all data and split data into training and validation samples (40% validation + 60% traning)\n",
    "data_train3 = fetch_20newsgroups(subset='train', categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "data_val3 = fetch_20newsgroups(subset='test', categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "dim_train3=len(data_train.target) # sample training size\n",
    "dim_val3=len(data_val.target) # sample validation size\n",
    "\n",
    "# Transform the dataset in matrix\n",
    "vectorizer = HashingVectorizer(stop_words='english', non_negative=True, n_features=10000)\n",
    "X_train3 = vectorizer.fit_transform(data_train3.data)\n",
    "X_val3 = vectorizer.transform(data_val3.data)\n",
    "y_train3 = data_train3.target==0\n",
    "y_val3 = data_val3.target==0\n",
    "\n",
    "# Running the Naive Bayes Model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train3.todense(), y_train3) # model dense matrix for sparse matrix\n",
    "\n",
    "# Calculating ROC Curve\n",
    "probs3 = clf.predict_proba(X_val3.todense())[:,1]\n",
    "FalsePositive, TruePositive, thresh = roc_curve(y_val3, probs3)\n",
    "name=\"DiffCat\"\n",
    "results3 = pd.DataFrame({\n",
    "        \"name\": name,\n",
    "        \"FalsePositive\": FalsePositive,\n",
    "        \"TruePositive\": TruePositive\n",
    "    })\n",
    "new_results=new_results.append(results3)\n",
    "ggplot(aes(x='FalsePositive', y='TruePositive', color='name'), data=new_results) + \\\n",
    "    geom_step(size=3) + \\\n",
    "    geom_abline(color=\"black\") + \\\n",
    "    ggtitle(\"Text Classification: ROC 3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Models Name\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space'\n",
    "]\n",
    "# import all data and split data into training and validation samples (40% validation + 60% traning)\n",
    "data_train4 = fetch_20newsgroups(subset='train', categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "data_val4 = fetch_20newsgroups(subset='test', categories=categories,\n",
    "        shuffle=True, random_state=42)\n",
    "dim_train4=len(data_train.target) # sample training size\n",
    "dim_val4=len(data_val.target) # sample validation size\n",
    "\n",
    "# Transform the dataset in matrix\n",
    "vectorizer = HashingVectorizer(stop_words='english', non_negative=True, n_features=10000)\n",
    "X_train4 = vectorizer.fit_transform(data_train4.data)\n",
    "X_val4 = vectorizer.transform(data_val4.data)\n",
    "y_train4 = data_train4.target==0\n",
    "y_val4 = data_val4.target==0\n",
    "\n",
    "# Diferent Models\n",
    "clfs = [\n",
    "    (\"MultinomialNB\", MultinomialNB()),\n",
    "    (\"KNeighborsClassifier\", KNeighborsClassifier()),\n",
    "    (\"RandomForestClassifier\", RandomForestClassifier()),\n",
    "    (\"SVM\", SVC(probability=True))\n",
    "]\n",
    "\n",
    "# Loop to calculate the model and ROC\n",
    "all_results = None\n",
    "for name, clf in clfs:\n",
    "    clf.fit(X_train4.todense(), y_train4)\n",
    "    probs = clf.predict_proba(X_val4.todense())[:,1]\n",
    "    FalsePositive, TruePositive, thresh = roc_curve(y_val4, probs)\n",
    "    results4 = pd.DataFrame({\n",
    "        \"name\": name,\n",
    "        \"FalsePositive\": FalsePositive,\n",
    "        \"TruePositive\": TruePositive\n",
    "    })\n",
    "    if all_results is None:\n",
    "        all_results = results4\n",
    "    else:\n",
    "        all_results = all_results.append(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot=ggplot(aes(x='FalsePositive', y='TruePositive', color='name'), data=all_results) + \\\n",
    "geom_step(size=3) + \\\n",
    "geom_abline(color=\"black\") + \\\n",
    "ggtitle(\"Text Classification: ROC 4 \\\\ green=NB|purple=RF|red=KN|blue=SVM\")\n",
    "print plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
